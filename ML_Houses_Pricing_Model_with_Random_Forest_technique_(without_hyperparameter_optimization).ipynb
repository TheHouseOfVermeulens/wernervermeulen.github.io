{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Houses Pricing Model with Random Forest technique (without hyperparameter optimization).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheHouseOfVermeulens/wernervermeulen.github.io/blob/master/ML_Houses_Pricing_Model_with_Random_Forest_technique_(without_hyperparameter_optimization).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzLuioUAd0nw",
        "colab_type": "text"
      },
      "source": [
        "Machine Learning Model build for Kaggle's 'the Housing Prices Competition'. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBnkX-oVeN-C",
        "colab_type": "text"
      },
      "source": [
        "RANDOM FOREST:\n",
        "The random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters. If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjJ4zi8uihPx",
        "colab_type": "text"
      },
      "source": [
        "Kaggle Competition: The Housing Prices (In class prediction model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pCqr-s8il62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code you have previously used to load data\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Set up code checking\n",
        "import os\n",
        "if not os.path.exists(\"../input/train.csv\"):\n",
        "    os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n",
        "    os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\") \n",
        "from learntools.core import binder\n",
        "binder.bind(globals())\n",
        "from learntools.machine_learning.ex7 import *\n",
        "\n",
        "# Path of the file to read. We changed the directory structure to simplify submitting to a competition\n",
        "iowa_file_path = '../input/train.csv'\n",
        "\n",
        "home_data = pd.read_csv(iowa_file_path)\n",
        "# Create target object and call it y\n",
        "y = home_data.SalePrice\n",
        "# Create X\n",
        "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
        "X = home_data[features]\n",
        "\n",
        "# Split into validation and training data\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
        "\n",
        "# Specify Model\n",
        "iowa_model = DecisionTreeRegressor(random_state=1)\n",
        "# Fit Model\n",
        "iowa_model.fit(train_X, train_y)\n",
        "\n",
        "# Make validation predictions and calculate mean absolute error\n",
        "val_predictions = iowa_model.predict(val_X)\n",
        "val_mae = mean_absolute_error(val_predictions, val_y)\n",
        "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
        "\n",
        "# Using best value for max_leaf_nodes\n",
        "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
        "iowa_model.fit(train_X, train_y)\n",
        "val_predictions = iowa_model.predict(val_X)\n",
        "val_mae = mean_absolute_error(val_predictions, val_y)\n",
        "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
        "\n",
        "# Define the model. Set random_state to 1\n",
        "rf_model = RandomForestRegressor(random_state=1)\n",
        "rf_model.fit(train_X, train_y)\n",
        "rf_val_predictions = rf_model.predict(val_X)\n",
        "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
        "\n",
        "print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xc1zfEvisiz",
        "colab_type": "text"
      },
      "source": [
        "If you run the above code with correct csv located. The following output return:\n",
        "\n",
        "```\n",
        "Validation MAE when not specifying max_leaf_nodes: 29,653\n",
        "Validation MAE for best value of max_leaf_nodes: 27,283\n",
        "Validation MAE for Random Forest Model: 22,762\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_cznhaBjAah",
        "colab_type": "text"
      },
      "source": [
        "Now create a new Random Forrest Model to improve on the above Decision Tree model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JDhWLztjO_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# To improve accuracy, create a new Random Forest model which you will train on all training data\n",
        "rf_model_on_full_data = RandomForestRegressor()\n",
        "\n",
        "# fit rf_model_on_full_data on all data from the training data\n",
        "rf_model_on_full_data.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkXwjJJUs8UY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "                      max_features='auto', max_leaf_nodes=None,\n",
        "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      min_samples_leaf=1, min_samples_split=2,\n",
        "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
        "                      n_jobs=None, oob_score=False, random_state=None,\n",
        "                      verbose=0, warm_start=False)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtuWo9RctAN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path to file you will use for predictions\n",
        "test_data_path = '../input/test.csv'\n",
        "\n",
        "# read test data file using pandas\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# create test_X which comes from test_data but includes only the columns you used for prediction.\n",
        "# The list of columns is stored in a variable called features\n",
        "test_X = test_data[features]\n",
        "\n",
        "# make predictions which we will submit. \n",
        "test_preds = rf_model_on_full_data.predict(test_X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2xFJjwoIPFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: Drop columns with missing values: \n",
        "# Fill in the line below: get names of columns with missing values\n",
        "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()] \n",
        "\n",
        "# Fill in the lines below: drop columns in training and validation data\n",
        "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
        "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp_RAU2DIeVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To obtain the MEA:\n",
        "print(\"MAE (Drop columns with missing values):\")\n",
        "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVxexCZVIiIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3: Imputation:\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Fill in the lines below: imputation\n",
        "____ # Your code here\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
        "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
        "\n",
        "# Fill in the lines below: imputation removed column names; put them back\n",
        "imputed_X_train.columns = X_train.columns\n",
        "imputed_X_valid.columns = X_valid.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx7HgQmyIxq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To obtain MEA for this approach: \n",
        "print(\"MAE (Imputation):\")\n",
        "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5_aXsqGI5zC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 4: Generate test predictions:\n",
        "# Preprocessed training and validation features\n",
        "# Imputation\n",
        "final_imputer = SimpleImputer(strategy='median')\n",
        "final_X_train = pd.DataFrame(final_imputer.fit_transform(X_train))\n",
        "final_X_valid = pd.DataFrame(final_imputer.transform(X_valid))\n",
        "\n",
        "# Imputation removed column names; put them back\n",
        "final_X_train.columns = X_train.columns\n",
        "final_X_valid.columns = X_valid.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byd-dhlJJXmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To train and evaluate the Random Forest model:\n",
        "# Define and fit model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "model.fit(final_X_train, y_train)\n",
        "\n",
        "# Get validation predictions and MAE\n",
        "preds_valid = model.predict(final_X_valid)\n",
        "print(\"MAE (Your approach):\")\n",
        "print(mean_absolute_error(y_valid, preds_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NioYljAPJvY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lastly: \n",
        "# Fill in the line below: preprocess test data\n",
        "final_X_test = pd.DataFrame(final_imputer.transform(X_test))\n",
        "\n",
        "# Fill in the line below: get test predictions\n",
        "preds_test = model.predict(final_X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8mYNtgntLRS",
        "colab_type": "text"
      },
      "source": [
        "My submission:\n",
        "\n",
        "Score:\n",
        "Complete\n",
        "\n",
        "[Jump to your position on the leaderboard ](https://www.kaggle.com/c/home-data-for-ml-course/leaderboard#score)"
      ]
    }
  ]
}